<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web-Based Intruder Detection</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
            color: #333;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 20px;
            text-align: center;
            color: #2c3e50;
        }
       #video-container {
            position: relative;
            border: 2px solid #3498db;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
           margin-bottom:20px;
           overflow:hidden; /* prevent out of bound canvas issues */
           display:flex;
           align-items:center;
           justify-content:center;
        }
        #canvas {
           position: absolute;
            top:0;
            left:0;
             pointer-events:none; /*  pass through events to video below */
        }
        #video {
           display: block;
          
            width: 100%;
            height: auto;
            max-width: 640px;
             max-height: 480px;
        }

        #controls {
            margin-top: 20px;
            text-align: center;
             display: flex;
             flex-direction: column;
            align-items:center;
            justify-content:center;
        }

        button, input[type="file"] {
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
            background-color: #3498db;
            color: #fff;
            border: none;
            border-radius: 5px;
             font-size:1em;
            transition: background-color 0.3s ease;
        }
         button:hover {
            background-color: #2980b9;
        }
        input[type="file"] {
             color:#fff;
              background-color: #3498db;
           font-size:1em;
        }
        input[type="file"]::file-selector-button {
             color: #fff;
           background-color: #2980b9;
           border:none;
           padding:10px 20px;
           border-radius:5px;
           transition: background-color 0.3s ease;
       }
      input[type="file"]::file-selector-button:hover {
         background-color: #1f6791;
      }
        #message {
            margin-top: 10px;
            text-align: center;
            font-weight: bold;
        }
        #captureButton {
             display: block;
             margin: 20px auto;
            padding: 10px 20px;
             cursor: pointer;
            background-color: #e74c3c;
            color: #fff;
            border: none;
            border-radius: 5px;
           font-size:1em;
           transition: background-color 0.3s ease;
        }
        #captureButton:hover {
           background-color: #c0392b;
        }

        @media (max-width: 768px) {
              #video {
                 width: 100%;
                 height: auto;
               }
           button, input[type="file"] {
             padding: 8px 16px;
           font-size:0.9em;
           }
           h1 {
              font-size:2em;
           }
        }
    </style>
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
</head>
<body>
    <h1>Real-time Intruder Detection System</h1>
   <div id="video-container">
      <video id="video" autoplay muted></video>
      <canvas id="canvas" width="640" height="480"></canvas>
    </div>

    <div id="controls">
        <button id="webcamButton">Start Webcam</button>
         <span> 또는 </span>
        <input type="file" id="fileInput" accept="video/*">
       <button id="captureButton">Start Recording</button>
    </div>
    <div id="message"></div>

   <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const webcamButton = document.getElementById('webcamButton');
        const fileInput = document.getElementById('fileInput');
        const captureButton = document.getElementById('captureButton');
         const messageDiv = document.getElementById('message');
        
        let poseModel;
        let faceModel;
        let prevKeypoints = null;
        let prevFaceBoxes = [];
        let prevAngles = {};
        const movementThreshold = 20;
        const angleChangeThreshold = 15;  // 임계값을 조정해서 민감도를 변경할 수 있습니다.
         const stayTimeThreshold = 5 * 1000; // 5 seconds
        let startTime = {};
        let mediaRecorder = null;
        let recordedChunks = [];
        let isRecording = false;
        let recognizedFaces = []; // Store recognized faces
        let captureCount = 0;
    
        async function loadModels() {
            try {
              poseModel = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {
                modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
            });
            faceModel = await faceDetection.createDetector(faceDetection.SupportedModels.MediaPipeFaceDetector);
           }
           catch(error) {
              console.error("Error loading models:", error);
          }
        }
       loadModels();
    
       function calculateAngle(a, b, c) {
          if (!a || !b || !c) {
               return 0;
           }
           const a_pos = {x: a.x, y:a.y};
          const b_pos = {x: b.x, y:b.y};
           const c_pos = {x: c.x, y:c.y};
           const radians = Math.atan2(c_pos.y - b_pos.y, c_pos.x - b_pos.x) - Math.atan2(a_pos.y - b_pos.y, a_pos.x - b_pos.x);
          let angle = Math.abs(radians * 180.0 / Math.PI);
            if (angle > 180.0) {
               angle = 360 - angle;
            }
            return angle;
        }
    
       async function detectAndAnalyze(video) {
            if (poseModel && faceModel) {
                try {
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    const poses = await poseModel.estimatePoses(video, { flipHorizontal: true });
                    const faces = await faceModel.estimateFaces(video);
                                        
                  if(poses && poses.length>0) {
                        const pose = poses[0]; // Assume only one person in the frame
                       drawKeypoints(pose.keypoints);
                         detectMovement(pose.keypoints);
                        detectSuspiciousBehavior(pose.keypoints);
                    }
                   if(faces && faces.length>0) {
                      detectAndRecognizeFaces(faces);
                      drawFaces(faces);
                   }
                } catch (error) {
                    console.error("Error detecting and analyzing:", error);
                 }
            }
          requestAnimationFrame(()=>detectAndAnalyze(video));
        }

        function drawKeypoints(keypoints) {
             ctx.fillStyle = "white";
            for(let i=0; i < keypoints.length; i++) {
                 const keypoint = keypoints[i];
                 if(keypoint.score > 0.5){
                    ctx.beginPath();
                     ctx.arc(keypoint.x, keypoint.y, 5, 0, 2*Math.PI);
                    ctx.fill();
                 }
            }
        }

         function detectMovement(keypoints) {
            if(prevKeypoints) {
               let totalMovement = 0;
                for (let i = 0; i < keypoints.length; i++) {
                     const prevKeypoint = prevKeypoints[i];
                   const keypoint = keypoints[i];
                    if(prevKeypoint && keypoint && prevKeypoint.score > 0.5 && keypoint.score >0.5) {
                        totalMovement += Math.sqrt(Math.pow(keypoint.x-prevKeypoint.x,2) + Math.pow(keypoint.y - prevKeypoint.y,2))
                    }
               }
                 if (totalMovement * canvas.width > movementThreshold) {
                   messageDiv.textContent = "Movement Detected!";
                   messageDiv.style.color = "red";
                    console.log(f"Total movement: {totalMovement * canvas.width:.2f}");
                      captureCanvas("movement");
                } else {
                    messageDiv.textContent = "";
                }
           }
            prevKeypoints = keypoints;
         }

         function detectSuspiciousBehavior(keypoints) {
            const leftElbow = keypoints[7];
            const leftShoulder = keypoints[5];
            const leftWrist = keypoints[9];
            const rightElbow = keypoints[8];
           const rightShoulder = keypoints[6];
             const rightWrist = keypoints[10];
          
             if(leftElbow && leftShoulder && leftWrist &&
                 rightElbow && rightShoulder && rightWrist &&
                leftElbow.score > 0.5 && leftShoulder.score > 0.5 && leftWrist.score > 0.5 &&
                rightElbow.score > 0.5 && rightShoulder.score > 0.5 && rightWrist.score > 0.5) {

                   const newLeftArmAngle = calculateAngle(leftShoulder, leftElbow, leftWrist);
                   const newRightArmAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);

                     if(prevAngles["leftArm"] && Math.abs(newLeftArmAngle - prevAngles["leftArm"]) > angleChangeThreshold){
                      messageDiv.textContent = "Suspicious arm movement detected";
                       messageDiv.style.color = "orange";
                        console.log("Suspicious arm movement detected");
                         captureCanvas("suspicious_arm");
                   }
                     if(prevAngles["rightArm"] && Math.abs(newRightArmAngle - prevAngles["rightArm"]) > angleChangeThreshold){
                        messageDiv.textContent = "Suspicious arm movement detected";
                       messageDiv.style.color = "orange";
                       console.log("Suspicious arm movement detected");
                        captureCanvas("suspicious_arm");
                    }
                     prevAngles["leftArm"] = newLeftArmAngle;
                   prevAngles["rightArm"] = newRightArmAngle;
           }
       }

         function drawFaces(faces) {
            ctx.strokeStyle = "red";
           for (const face of faces) {
               const box = face.box;
              ctx.strokeRect(box.x, box.y, box.width, box.height);
            }
         }

         function detectAndRecognizeFaces(faces) {
            for(let face of faces) {
                const box = face.box;
               const faceId = `${box.x}_${box.y}_${box.width}_${box.height}`;
               let faceFound = recognizedFaces.find(x=>x.faceId == faceId)
               if (!faceFound) {
                    recognizedFaces.push({faceId:faceId,time: new Date().toLocaleString()});
                     messageDiv.textContent = `New face detected at ${ new Date().toLocaleString()}`;
                   messageDiv.style.color = "blue";
                    console.log(`New face detected at ${ new Date().toLocaleString()}`);
                    captureCanvas("face");
              }
            }
        }


         async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                 video.srcObject = stream;
                   video.onloadedmetadata = () => {
                       video.play();
                     detectAndAnalyze(video);
                 }
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
       }
   
       function handleFile(event) {
            const file = event.target.files[0];
             if (file) {
                 video.src = URL.createObjectURL(file);
                   video.onloadedmetadata = () => {
                       video.play();
                    detectAndAnalyze(video);
                }
            }
       }


        async function startRecording() {
           if (!isRecording) {
               recordedChunks = [];
               const stream = canvas.captureStream(30);
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=vp9' });
               mediaRecorder.ondataavailable = handleDataAvailable;
               mediaRecorder.start();
               captureButton.textContent = "Stop Recording";
              isRecording = true;
           } else {
                mediaRecorder.stop();
                captureButton.textContent = "Start Recording";
              isRecording = false;
           }
       }

        function handleDataAvailable(event){
           if (event.data && event.data.size >0 ) {
                recordedChunks.push(event.data);
                downloadVideo();
           }
        }

         function downloadVideo() {
            const blob = new Blob(recordedChunks, { type: "video/webm" });
           const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
              a.download = 'captured.webm';
             a.style.display = 'none';
           document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
           recordedChunks = [];
         }
    
         function captureCanvas(type){
           const image = canvas.toDataURL("image/png");
            const a = document.createElement('a');
             a.href = image;
            a.download = `captured_${type}_${captureCount}.png`;
            a.style.display = 'none';
            document.body.appendChild(a);
             a.click();
           document.body.removeChild(a);
           captureCount++;
        }

       startWebcam();
       webcamButton.addEventListener('click', startWebcam);
      fileInput.addEventListener('change', handleFile);
        captureButton.addEventListener('click', startRecording);
    </script>
</body>
</html>
